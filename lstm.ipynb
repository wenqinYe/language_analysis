{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tag.stanford import StanfordPOSTagger as tagger\n",
    "import treetaggerwrapper\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, unique_characters=[], data=[], shuffle=False):\n",
    "        self.unique_characters = unique_characters\n",
    "        \n",
    "        self.unique_characters.insert(0, u\"<EOS>\") \n",
    "        self.unique_characters.insert(0, u\"<GO>\") \n",
    "        self.unique_characters.insert(0, u\"<PAD>\") \n",
    "        \n",
    "        self.num_unique_chars = len(self.unique_characters)\n",
    "        \n",
    "        self.char2index = {v: i for i, v in enumerate(self.unique_characters)}\n",
    "        self.index2char = {i: v for i, v in enumerate(self.unique_characters)}\n",
    "        \n",
    "        self.embedding_size = 5\n",
    "        self.embeddings = tf.Variable(tf.random_uniform([len(self.char2index), self.embedding_size], -1.0, 1.0))\n",
    "        \n",
    "        self.current_index = 0\n",
    "        \n",
    "        self.data = np.array(data)\n",
    "        self.length = len(self.data)\n",
    "        self.permuted_indices = np.random.permutation(self.length)\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        \n",
    "    def to_one_hot(self, batches, as_tf_tensor=False):\n",
    "        \"\"\"\n",
    "        Takes data of the shape [batch, characters]\n",
    "        and converts it into a one hot representation\n",
    "        to be used by a LSTM or other neural network\n",
    "        Example: \n",
    "                [\n",
    "                    ['a', 'b'],\n",
    "                    ['a', 'c']\n",
    "                ]\n",
    "                Converts into one-hot representation ->\n",
    "                [\n",
    "                    [[1, 0, 0], [0, 1, 0]],\n",
    "                    [[1, 0, 0], [0, 0, 1]]\n",
    "                ]\n",
    "        \n",
    "        Params:\n",
    "            batches: Batch of character input data\n",
    "            as_tensor: If the one_hot representation should be a np array or \n",
    "                       a tensorflow tensor.\n",
    "            \n",
    "        Returns:\n",
    "            A one hot tensor representation of the input batch data\n",
    "        \"\"\"\n",
    "#         char_indices = []\n",
    "#         for batch in batches:\n",
    "#             char_indices.append([self.char2index[char] for char in batch])\n",
    "            \n",
    "        one_hot = tf.one_hot(batches, depth=self.num_unique_chars)\n",
    "        if not as_tf_tensor:\n",
    "            one_hot = np.zeros(one_hot.shape)\n",
    "            for batch_index, batch in enumerate(batches):\n",
    "                for index, one_hot_index in enumerate(batch):\n",
    "                    one_hot[batch_index, index, one_hot_index] = 1\n",
    "        return one_hot \n",
    "    \n",
    "    def embedding(self, batch):\n",
    "        return tf.nn.embedding_lookup(self.embeddings, batch) \n",
    "    \n",
    "    def set_data(self, data, sort_length=False):\n",
    "        self.data = np.array(data)\n",
    "        self.length = len(data)\n",
    "        self.permuted_indices = np.random.permutation(self.length)\n",
    "    \n",
    "    def next(self, number):\n",
    "        \"\"\"\n",
    "        This function automatically zero pads the data so that all sequences\n",
    "        are the same length.\n",
    "        \"\"\"\n",
    "        if self.shuffle:\n",
    "            batch_indices = self.permuted_indices[self.current_index: self.current_index+number]\n",
    "            batch = self.data[batch_indices]\n",
    "        else:\n",
    "            batch = self.data[self.current_index: self.current_index+number]\n",
    "        \n",
    "        max = 0\n",
    "        for item in batch:\n",
    "            if len(item) > max:\n",
    "                max = len(item)\n",
    "                \n",
    "        padded_batch = np.zeros((len(batch), max))\n",
    "        \n",
    "        for idx, item in enumerate(batch):\n",
    "            padded_batch[idx, np.arange(len(item))] = item\n",
    "            \n",
    "        if self.current_index + number >= len(self.data):\n",
    "            self.current_index = 0\n",
    "        else:\n",
    "            self.current_index += number\n",
    "        \n",
    "        return padded_batch\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def french_to_universal(french_pos_tagged):\n",
    "    \"\"\"\n",
    "    French POS to Universal Mapping credit to:\n",
    "    https://stackoverflow.com/questions/27513185/simplifying-the-french-pos-tag-set-with-nltk\n",
    "    \"\"\"\n",
    "    french_to_universal = {\n",
    "        u\"ADJ\": u\"ADJ\",\n",
    "        u\"ADJWH\": u\"ADJ\",\n",
    "        u\"ADV\": u\"ADV\",\n",
    "        u\"ADVWH\":u\"ADV\",\n",
    "        u\"CC\": u\"CONJ\",    \n",
    "        u\"CLO\":u\"PRON\",\n",
    "        u\"CLR\": u\"PRON\",\n",
    "        u\"CLS\": u\"PRON\",\n",
    "        u\"CS\": u\"CONJ\",\n",
    "        u\"DET\": u\"DET\",\n",
    "        u\"DETWH\": u\"DET\",\n",
    "        u\"ET\": u\"X\",\n",
    "        u\"NC\": u\"NOUN\",\n",
    "        u\"NPP\": u\"NOUN\",\n",
    "        u\"P\": u\"ADP\",\n",
    "        u\"PUNC\": u\".\",\n",
    "        u\"PRO\": u\"PRON\",\n",
    "        u\"PROREL\": u\"PRON\",\n",
    "        u\"PROWH\": u\"PRON\",\n",
    "        u\"V\": u\"VERB\",\n",
    "        u\"VIMP\": u\"VERB\",\n",
    "        u\"VINF\": u\"VERB\",\n",
    "        u\"VPP\": u\"VERB\",\n",
    "        u\"VPR\": u\"VERB\",\n",
    "        u\"VS\": u\"VERB\",\n",
    "        u\"N\": u\"NOUN\",\n",
    "        u\"I\": u\"X\",\n",
    "        u\"PREF\": u\"PRT\",\n",
    "        u\"C\": u\"CONJ\",\n",
    "        u\"CL\": u\"PRON\",\n",
    "    }\n",
    "    \n",
    "    return [(word, french_to_universal[tag]) for word, tag in french_pos_tagged]\n",
    "\n",
    "def english_to_universal(english_pos_tagged):\n",
    "    return [(word, nltk.tag.map_tag('en-ptb', 'universal', pos)) for word, pos in english_pos_tagged]\n",
    "\n",
    "french_data = Data(unique_characters=[u'ADV', u'NOUN', u'ADP', u'PRT', u'DET', u'.', u'PRON', u'VERB', u'X', u'NUM', u'CONJ', u'ADJ'])\n",
    "english_data = Data(unique_characters=[u'ADV', u'NOUN', u'ADP', u'PRT', u'DET', u'.', u'PRON', u'VERB', u'X', u'NUM', u'CONJ', u'ADJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jar_path = \"/Users/wenqin/Documents/datasets/stanford-postagger-2017/stanford-postagger-3.8.0.jar\"\n",
    "french_tagger = tagger(\"/Users/wenqin/Documents/datasets/stanford-postagger-2017/models/french.tagger\", path_to_jar=jar_path)\n",
    "\n",
    "base_path = \"/Users/wenqin/Documents/datasets/texts/\"\n",
    "\n",
    "french_file = open(base_path + \"french/book1.txt\").read()\n",
    "french_tagged = french_tagger.tag(french_file.split(\" \"))\n",
    "french_tagged = french_to_universal(french_tagged)\n",
    "\n",
    "english_file = open(base_path + \"english/pride_and_prejudice.txt\").read()\n",
    "english_tagged = nltk.pos_tag(nltk.word_tokenize(unicode(english_file, 'utf-8')))\n",
    "english_tagged = english_to_universal(english_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def numerical_representation(tagged_words, data_class, lang='fr', sort_by_length=True):\n",
    "    sentences_tags = [[]]\n",
    "    \n",
    "    for word, tag in tagged_words:\n",
    "        sentences_tags[-1].append((word, tag))\n",
    "        if lang == 'fr':\n",
    "            if word[-1] == \".\":\n",
    "                sentences_tags[-1].append((u\".\", u\".\"))\n",
    "                sentences_tags.append([])\n",
    "        else:\n",
    "            if word == \".\":\n",
    "                sentences_tags.append([])\n",
    "    \n",
    "    data = []\n",
    "    for sentence_tags in sentences_tags:\n",
    "        data.append([data_class.char2index[tag] for word, tag in sentence_tags])\n",
    "        \n",
    "    return sorted(data, key=len)\n",
    "\n",
    "english_data.set_data(numerical_representation(french_tagged, english_data))\n",
    "french_data.set_data(numerical_representation(french_tagged, french_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTM_Cell:\n",
    "    def __init__(self, time_steps=None, input_size=None, cell_size=None, learning_rate=1e-3):\n",
    "        assert cell_size is not None and input_size is not None\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.cell_size = cell_size\n",
    "        \n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, None, input_size], name=\"lstm_inputs\")\n",
    "        self.targets = tf.placeholder(tf.float32, shape=[None, None, input_size], name=\"lstm_targets\")\n",
    "        \n",
    "        self.w_f = tf.Variable(tf.random_normal(shape=[self.input_size, self.cell_size]), name=\"w_f\")\n",
    "        self.u_f = tf.Variable(tf.random_normal(shape=[self.cell_size, self.cell_size]), name=\"u_f\")\n",
    "        self.b_f = tf.Variable(tf.constant(0., shape=[self.cell_size]), name=\"b_f\")\n",
    "\n",
    "        self.w_i = tf.Variable(tf.random_normal(shape=[self.input_size, self.cell_size]), name=\"w_i\")\n",
    "        self.u_i = tf.Variable(tf.random_normal(shape=[self.cell_size, self.cell_size]), name=\"u_i\")\n",
    "        self.b_i = tf.Variable(tf.constant(0., shape=[self.cell_size]), name=\"b_i\")\n",
    "\n",
    "        self.w_o = tf.Variable(tf.random_normal(shape=[self.input_size, self.cell_size]), name=\"w_o\")\n",
    "        self.u_o = tf.Variable(tf.random_normal(shape=[self.cell_size, self.cell_size]), name=\"u_o\")\n",
    "        self.b_o = tf.Variable(tf.constant(0., shape=[self.cell_size]), name=\"b_0\")\n",
    "        \n",
    "        self.w_c = tf.Variable(tf.random_normal(shape=[self.input_size, self.cell_size]), name=\"w_c\")\n",
    "        self.u_c = tf.Variable(tf.random_normal(shape=[self.cell_size, self.cell_size]), name=\"u_cs\")\n",
    "        self.b_c = tf.Variable(tf.constant(0., shape=[self.cell_size]), name=\"b_c\")\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.outputs = None\n",
    "        self.last_hidden_state = None\n",
    "        self.last_cell_state = None\n",
    "        \n",
    "        self.time_steps = time_steps\n",
    "        \n",
    "    def call(self, state_tuple, x):\n",
    "        previous_hidden, previous_cell_state = tf.unstack(state_tuple)\n",
    "        \n",
    "        f = tf.nn.sigmoid(tf.matmul(x, self.w_f) + tf.matmul(previous_hidden, self.u_f) + self.b_f)\n",
    "        i = tf.nn.sigmoid(tf.matmul(x, self.w_i) + tf.matmul(previous_hidden, self.u_i) + self.b_i)\n",
    "        o = tf.nn.sigmoid(tf.matmul(x, self.w_o) + tf.matmul(previous_hidden, self.u_o) + self.b_o)\n",
    "        \n",
    "        cell_state_additions = tf.nn.tanh(tf.matmul(x, self.w_c) + tf.matmul(x, self.w_c) + self.b_c)\n",
    "        \n",
    "        cell_state = tf.multiply(cell_state_additions, i) + tf.multiply(previous_cell_state, f)\n",
    "        new_hidden = tf.nn.tanh(tf.multiply(cell_state, o))\n",
    "        \n",
    "        return tf.stack([new_hidden, cell_state])\n",
    "    \n",
    "    def dynamic_output_run(self, state_tuple=None, current_time_step=1, history=[]):\n",
    "        \"\"\"\n",
    "        Runs the LSTM cell by using its output as the input into a new time_step\n",
    "        \"\"\"\n",
    "        assert state_tuple is not None\n",
    " \n",
    "        hidden_state, cell_state = tf.unstack(state_tuple)\n",
    "        new_state_tuple = self.call(state_tuple, hidden_state)\n",
    "        new_hidden_state, new_cell_state = tf.unstack(new_state_tuple)\n",
    "        history.append(new_hidden_state)\n",
    "        \n",
    "        if current_time_step < self.time_steps:\n",
    "             self.dynamic_output_run(new_state_tuple, current_time_step=current_time_step+1, history=history)\n",
    "        \n",
    "        return tf.transpose(tf.stack(history, name='dynamic_output_run'), [1, 0, 2])\n",
    "    \n",
    "    def dynamic_rnn(self, input_sequence=None, dynamic_output=False, initial_state_tuple=None):\n",
    "        input_sequence = tf.transpose(input_sequence, [1, 0, 2]) #tranpose to allow for batch processing    \n",
    "        \n",
    "        batch_items = tf.shape(input_sequence)[1]\n",
    "        \n",
    "        if initial_state_tuple is None:\n",
    "            initial_state_tuple = self.initial_state_tuple(batch_items)\n",
    "        \n",
    "        state_tuples = tf.scan(self.call, input_sequence, initializer=initial_state_tuple)\n",
    "        \n",
    "        hidden_states, cell_states = self.split_state_tuples(state_tuples)\n",
    "        last_hidden_states, last_cell_states = tf.unstack(tf.gather(state_tuples, tf.shape(state_tuples)[1]))\n",
    "        \n",
    "        return hidden_states, cell_states, tf.stack([last_hidden_states, last_cell_states])\n",
    "        \n",
    "    def split_state_tuples(self, state_tuples):\n",
    "        \"\"\"\n",
    "        For splitting batches of state_tuples that are time_major.\n",
    "        To split a single state_tuple use \"unstack\"\n",
    "        \"\"\"\n",
    "        hidden_states, cell_states = tf.split(state_tuples, 2, axis=1)\n",
    "        #permute the shapes to make the data batch major instead of time major\n",
    "        \n",
    "        hidden_states = tf.squeeze(hidden_states, axis=1) #axis-1 is the now irrelevant state-tuple axis\n",
    "        cell_states = tf.squeeze(cell_states, axis=1)     #axis-1 is the now irrelevant state-tuple axis\n",
    "        \n",
    "        hidden_states = tf.transpose(hidden_states, [1, 0, 2])\n",
    "        cell_states = tf.transpose(cell_states, [1, 0, 2]) \n",
    "        \n",
    "        return hidden_states, cell_states\n",
    "    \n",
    "    def initial_state_tuple(self, batch_items):\n",
    "        initial_hidden = tf.zeros([batch_items, self.cell_size], name='hidden')\n",
    "        initial_cell_state = tf.zeros([batch_items, self.cell_size], name='cell_state')\n",
    "        initial_state_tuple = tf.stack([initial_hidden, initial_cell_state])\n",
    "        \n",
    "        return initial_state_tuple\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        hidden_states, cell_states, last_state_tuples = self.dynamic_rnn(self.inputs)\n",
    "        self.outputs = [hidden_states, cell_states]\n",
    "    \n",
    "        self.last_hidden_state, self.last_cell_state = tf.unstack(last_state_tuples)\n",
    "        \n",
    "        return tf.reduce_mean(tf.squared_difference(self.targets, hidden_states))\n",
    "    \n",
    "class Optimizer:\n",
    "    def __init__(self, model, learning_rate=1e-2):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(model.loss)\n",
    "        \n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def run_training(self, inputs, targets, epochs=10, print_interval=10):\n",
    "        np.set_printoptions(suppress=True)\n",
    "        for i in range(epochs):\n",
    "            if print_interval is not None and i % print_interval == 0:\n",
    "                print self.sess.run(self.model.predictions, {self.model.inputs: inputs, self.model.targets: targets})\n",
    "                print \"-\" * 50\n",
    "            self.sess.run(self.optimizer, {self.model.inputs: inputs, self.model.targets: targets})\n",
    "            \n",
    "    def plot_cells(self):\n",
    "        cell_state = self.sess.run(self.c)\n",
    "        print cell_state\n",
    "        plt.matshow(cell_state, cmap='Blues'), plt.show()\n",
    "        \n",
    "class Seq2SeqModel:\n",
    "    def __init__(self, data=english_data):\n",
    "        self.encoder_cell = LSTM_Cell(time_steps=3, input_size=5, cell_size=10)\n",
    "        self.decoder_cell = LSTM_Cell(time_steps=3, input_size=5, cell_size=10)\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        self.inputs = tf.placeholder(dtype=tf.int32, shape=(None, None))\n",
    "        self.encoder_cell.inputs = data.embedding(self.inputs)\n",
    "        self.targets = tf.placeholder(dtype=tf.float32, shape=(None, None, 15))\n",
    "        \n",
    "        self.hidden_states, self.cell_states, self.last_state_tuple = self.encoder_cell.dynamic_rnn(self.encoder_cell.inputs)\n",
    "        #self.outputs = self.decoder_cell.dynamic_output_run(state_tuple=self.last_state_tuple, history=[])\n",
    "        self.outputs, self.cell_states, _ = self.decoder_cell.dynamic_rnn(self.encoder_cell.inputs, initial_state_tuple=self.last_state_tuple)\n",
    "        \n",
    "        self.predictions = tf.layers.dense(self.hidden_states, 15, activation=tf.nn.tanh)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.squared_difference(self.targets, self.predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(data=english_data)\n",
    "optimizer = Optimizer(model)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print epoch\n",
    "    for _ in range(english_data.length/16):\n",
    "        input_sequence = english_data.next(16).astype(\"int\")\n",
    "        target_sequence = english_data.to_one_hot(input_sequence)\n",
    "        optimizer.run_training(input_sequence, target_sequence, epochs=1, print_interval=None)\n",
    "        \n",
    "print optimizer.sess.run([optimizer.model.predictions], {optimizer.model.inputs: english_data.next(1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"=\" * 100\n",
    "print \"TRAINING ON FRENCH\"\n",
    "french_model = Seq2SeqModel(data=french_data)\n",
    "french_optimizer = Optimizer(french_model)\n",
    "for epoch in range(5):\n",
    "    print epoch\n",
    "    for _ in range(french_data.length/16):\n",
    "        input_sequence = french_data.next(16).astype(\"int\")\n",
    "        target_sequence = french_data.to_one_hot(input_sequence)\n",
    "        french_optimizer.run_training(input_sequence, target_sequence, epochs=1, print_interval=None)\n",
    "        \n",
    "print french_optimizer.sess.run([french_optimizer.model.predictions], {french_optimizer.model.inputs: french_data.next(1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 14 nearest neighbors...\n",
      "[t-SNE] Indexed 15 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 15 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 15 / 15\n",
      "[t-SNE] Mean sigma: 1.092538\n",
      "[t-SNE] Computed conditional probabilities in 0.002s\n",
      "[t-SNE] Iteration 50: error = 67.1733170, gradient norm = 0.3090064 (50 iterations in 0.019s)\n",
      "[t-SNE] Iteration 100: error = 48.4069977, gradient norm = 0.1878501 (50 iterations in 0.023s)\n",
      "[t-SNE] Iteration 150: error = 56.5644989, gradient norm = 0.1594386 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 200: error = 52.2310104, gradient norm = 0.3700641 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 250: error = 68.2152481, gradient norm = 0.2569684 (50 iterations in 0.013s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 68.215248\n",
      "[t-SNE] Iteration 300: error = 1.1422688, gradient norm = 0.0010909 (50 iterations in 0.015s)\n",
      "[t-SNE] Iteration 350: error = 0.8159330, gradient norm = 0.0006306 (50 iterations in 0.012s)\n",
      "[t-SNE] Iteration 400: error = 0.6450559, gradient norm = 0.0003823 (50 iterations in 0.015s)\n",
      "[t-SNE] Iteration 450: error = 0.5552657, gradient norm = 0.0002273 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 500: error = 0.5086540, gradient norm = 0.0001367 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 550: error = 0.4903549, gradient norm = 0.0000792 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 600: error = 0.4846926, gradient norm = 0.0000543 (50 iterations in 0.012s)\n",
      "[t-SNE] Iteration 650: error = 0.4802426, gradient norm = 0.0000418 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 700: error = 0.4769654, gradient norm = 0.0000393 (50 iterations in 0.017s)\n",
      "[t-SNE] Iteration 750: error = 0.4741992, gradient norm = 0.0000378 (50 iterations in 0.015s)\n",
      "[t-SNE] Iteration 800: error = 0.4713607, gradient norm = 0.0000293 (50 iterations in 0.020s)\n",
      "[t-SNE] Iteration 850: error = 0.4705853, gradient norm = 0.0000187 (50 iterations in 0.017s)\n",
      "[t-SNE] Iteration 900: error = 0.4703110, gradient norm = 0.0000220 (50 iterations in 0.015s)\n",
      "[t-SNE] Iteration 950: error = 0.4675555, gradient norm = 0.0000540 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 1000: error = 0.4424803, gradient norm = 0.0002002 (50 iterations in 0.014s)\n",
      "[t-SNE] Error after 1000 iterations: 0.442480\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dd1fe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(300)\n",
    "embeddings = english_data.embeddings\n",
    "X_english = optimizer.sess.run(embeddings)\n",
    "res_english = TSNE(n_components=2, verbose=2, perplexity=5).fit_transform(X_english)\n",
    "x, y = res_english.T\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "for i, txt in enumerate(english_data.unique_characters):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 14 nearest neighbors...\n",
      "[t-SNE] Indexed 15 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 15 samples in 0.000s...\n",
      "[t-SNE] Computed conditional probabilities for sample 15 / 15\n",
      "[t-SNE] Mean sigma: 0.802394\n",
      "[t-SNE] Computed conditional probabilities in 0.001s\n",
      "[t-SNE] Iteration 50: error = 52.4626579, gradient norm = 0.1964100 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 100: error = 58.8850670, gradient norm = 0.2956732 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 150: error = 64.9974747, gradient norm = 0.1955538 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 200: error = 54.1326103, gradient norm = 0.1912456 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 250: error = 76.9935379, gradient norm = 0.7933131 (50 iterations in 0.013s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 76.993538\n",
      "[t-SNE] Iteration 300: error = 1.1658531, gradient norm = 0.0011867 (50 iterations in 0.016s)\n",
      "[t-SNE] Iteration 350: error = 0.9588557, gradient norm = 0.0004574 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 400: error = 0.7543217, gradient norm = 0.0006421 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 450: error = 0.6779855, gradient norm = 0.0003587 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 500: error = 0.5724756, gradient norm = 0.0002930 (50 iterations in 0.012s)\n",
      "[t-SNE] Iteration 550: error = 0.5478066, gradient norm = 0.0000773 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 600: error = 0.5023522, gradient norm = 0.0003147 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 650: error = 0.3850679, gradient norm = 0.0004473 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 700: error = 0.3519181, gradient norm = 0.0003038 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 750: error = 0.2988516, gradient norm = 0.0001637 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 800: error = 0.2889399, gradient norm = 0.0000723 (50 iterations in 0.017s)\n",
      "[t-SNE] Iteration 850: error = 0.2873997, gradient norm = 0.0000358 (50 iterations in 0.023s)\n",
      "[t-SNE] Iteration 900: error = 0.2871542, gradient norm = 0.0000252 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 950: error = 0.2869052, gradient norm = 0.0000248 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 1000: error = 0.2865569, gradient norm = 0.0000280 (50 iterations in 0.012s)\n",
      "[t-SNE] Error after 1000 iterations: 0.286557\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD9CAYAAAB0i+q4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFRUREfGMioqIiHjm/wG9WAqG3uZCpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f890d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(300)\n",
    "embeddings = french_data.embeddings\n",
    "X_french = french_optimizer.sess.run(embeddings)\n",
    "res_french = TSNE(n_components=2, verbose=2, perplexity=5).fit_transform(X_french)\n",
    "x, y = res_french.T\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "for i, txt in enumerate(french_data.unique_characters):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "visited = []\n",
    "for pos in english_data.unique_characters:\n",
    "    visited.append(pos)\n",
    "    if pos[-1] == \">\" or pos == u\"X\" or pos == u\".\":\n",
    "        continue\n",
    "    for second_pos in english_data.unique_characters:\n",
    "        if second_pos in visited:\n",
    "            continue\n",
    "        if second_pos[-1] == \">\" or second_pos == u\"X\" or second_pos == u\".\":\n",
    "            continue\n",
    "        idx1 = english_data.char2index[pos]\n",
    "        idx2 = english_data.char2index[second_pos]\n",
    "        diff_french = np.linalg.norm(X_french[idx1] - X_french[idx2])\n",
    "        diff_english = np.linalg.norm(X_english[idx1] - X_english[idx2])\n",
    "        \n",
    "        diffs.append([pos, second_pos, diff_french, diff_english, np.abs(diff_french-diff_english)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POS1', 'POS2', 'French distance', 'English distance', 'Difference in language distance']\n",
      "[u'VERB', u'NUM', 1.8247626, 1.8020245, 0.022738099]\n",
      "[u'ADV', u'NUM', 2.365937, 2.3032146, 0.062722445]\n",
      "[u'ADV', u'PRT', 1.8472359, 1.7683926, 0.078843355]\n",
      "[u'ADP', u'CONJ', 1.4894204, 1.6267277, 0.13730729]\n",
      "[u'NOUN', u'DET', 2.8471708, 2.6858387, 0.16133213]\n",
      "[u'ADP', u'ADJ', 2.4979281, 2.6593592, 0.16143107]\n",
      "[u'NOUN', u'PRT', 2.1778231, 2.3997245, 0.22190142]\n",
      "[u'PRT', u'PRON', 1.0737046, 1.30162, 0.22791541]\n",
      "[u'ADP', u'PRON', 2.4608812, 2.7418683, 0.28098702]\n",
      "[u'PRON', u'CONJ', 1.955707, 2.2442217, 0.28851473]\n",
      "[u'PRT', u'ADJ', 2.5628846, 2.8555748, 0.29269028]\n",
      "[u'NOUN', u'ADJ', 2.4969866, 2.8114889, 0.31450224]\n",
      "[u'NOUN', u'ADP', 2.4770756, 2.8343289, 0.35725331]\n",
      "[u'CONJ', u'ADJ', 2.2189159, 1.8611804, 0.35773551]\n",
      "[u'PRT', u'NUM', 1.9371662, 2.2966437, 0.35947752]\n",
      "[u'DET', u'ADJ', 3.3750968, 3.0076208, 0.36747599]\n",
      "[u'NOUN', u'VERB', 2.5135429, 2.1404622, 0.37308073]\n",
      "[u'ADV', u'ADJ', 3.2653687, 2.8669457, 0.39842296]\n",
      "[u'ADV', u'NOUN', 2.2930245, 2.7387357, 0.44571114]\n",
      "[u'NUM', u'ADJ', 2.4119914, 2.8854053, 0.47341394]\n",
      "[u'DET', u'VERB', 2.1818521, 2.6941483, 0.5122962]\n",
      "[u'ADV', u'CONJ', 1.8599379, 2.4060977, 0.54615974]\n",
      "[u'PRON', u'ADJ', 3.3927524, 2.825865, 0.56688738]\n",
      "[u'NOUN', u'CONJ', 1.8690979, 2.4982305, 0.62913251]\n",
      "[u'PRT', u'CONJ', 1.3966459, 2.0286291, 0.63198316]\n",
      "[u'VERB', u'CONJ', 1.9728312, 2.6431777, 0.6703465]\n",
      "[u'ADV', u'VERB', 2.038991, 1.3681138, 0.67087722]\n",
      "[u'PRT', u'VERB', 1.4099414, 2.3749886, 0.96504712]\n",
      "[u'ADP', u'VERB', 1.7599832, 2.7546163, 0.99463308]\n",
      "[u'NOUN', u'PRON', 2.7335031, 1.7303913, 1.0031118]\n",
      "[u'PRON', u'VERB', 2.4531488, 1.3821172, 1.0710317]\n",
      "[u'VERB', u'ADJ', 2.0535831, 3.1390347, 1.0854516]\n",
      "[u'DET', u'NUM', 1.6498092, 2.8079407, 1.1581315]\n",
      "[u'NUM', u'CONJ', 1.5644904, 2.799438, 1.2349476]\n",
      "[u'PRON', u'NUM', 2.5961673, 1.3408949, 1.2552724]\n",
      "[u'ADV', u'PRON', 2.5022438, 1.1929679, 1.3092759]\n",
      "[u'DET', u'PRON', 2.0059705, 3.4350502, 1.4290798]\n",
      "[u'ADP', u'PRT', 1.7097071, 3.1527898, 1.4430827]\n",
      "[u'ADP', u'NUM', 1.6008577, 3.1053207, 1.504463]\n",
      "[u'ADV', u'ADP', 1.2364862, 2.8206251, 1.5841389]\n",
      "[u'DET', u'CONJ', 1.5021852, 3.4540644, 1.9518791]\n",
      "[u'ADP', u'DET', 1.4593436, 3.5983441, 2.1390004]\n",
      "[u'ADV', u'DET', 1.3074658, 3.6332319, 2.3257661]\n",
      "[u'NOUN', u'NUM', 3.2212257, 0.85112906, 2.3700967]\n",
      "[u'PRT', u'DET', 1.6238433, 4.0888052, 2.464962]\n"
     ]
    }
   ],
   "source": [
    "diffs = sorted(diffs, key=lambda x: x[4])\n",
    "print [\"POS1\", \"POS2\", \"French distance\", \"English distance\", \"Difference in language distance\"]\n",
    "for diff in diffs:\n",
    "    print diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Il', u'PRON'), (u\"l'a\", u'VERB'), (u'tapot\\xe9', u'VERB'), (u'doucement', u'ADV'), (u'sur', u'ADP'), (u'le', u'DET'), (u'dos', u'NOUN')]\n",
      "[('he', u'PRON'), ('gently', u'ADV'), ('patted', u'VERB'), ('her', u'PRON'), ('on', u'ADP'), ('the', u'DET'), ('back', u'NOUN')]\n",
      "====================================================================================================\n",
      "[(u'I', u'ADJ'), (u'wash', u'NOUN'), (u'myself.', u'ADJ')]\n",
      "[('Je', u'NOUN'), ('me', u'PRON'), ('lave.', u'VERB')]\n"
     ]
    }
   ],
   "source": [
    "print french_to_universal(french_tagger.tag(\"Il l'a tapot doucement sur le dos\".split(\" \")))\n",
    "print english_to_universal(nltk.pos_tag(\"he gently patted her on the back\".split(\" \")))\n",
    "\n",
    "print \"=\" * 100\n",
    "print french_to_universal(french_tagger.tag(\"I wash myself.\".split(\" \")))\n",
    "print english_to_universal(nltk.pos_tag(\"Je me lave.\".split(\" \")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
